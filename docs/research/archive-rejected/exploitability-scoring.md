# Exploitability Scoring Research

**Date:** October 16, 2025
**Status:** Research Complete - Implementation Pending
**Purpose:** Evaluate approaches for creating a single predictive "Exploitability Score" for domains based on detected technologies and vulnerabilities

## Executive Summary

This research evaluates different vulnerability scoring and exploitability prediction systems to determine the best approach for calculating a domain-level exploitability score based on detected technologies, CVEs, CWEs, and other security indicators.

**Key Recommendation:** Implement a hybrid scoring approach combining EPSS (Exploit Prediction Scoring System), KEV (Known Exploited Vulnerabilities) weighting, and CVSS severity with CWE-based factors to create a 0-100 normalized Exploitability Score.

## Problem Statement

We currently detect:
- Technologies used by domains (WordPress, React, Laravel, etc.)
- CVE counts by severity (Critical, High, Medium, Low, KEV)
- CWE categories (weakness types like XSS, SQL Injection, etc.)

**Goal:** Create a single predictive score indicating how exploitable a domain is, enabling prioritization of remediation efforts.

## Research Findings

### 1. EPSS (Exploit Prediction Scoring System)

**What it is:** A data-driven framework that estimates the probability a software vulnerability will be exploited in the wild within the next 30 days.

**Key Characteristics:**
- Score range: 0.0 to 1.0 (0% to 100% probability)
- Updates: Daily
- Prediction window: 30 days
- Accuracy: ROC AUC 0.838
- Cost: Free

**Performance Metrics:**
- 82% performance improvement over earlier methods
- 8x reduction in remediation workload vs CVSS-only strategies
- 80% reduction in false positives
- Only 2.3% of CVSS â‰¥7.0 vulnerabilities are actually exploited

**Data Sources:**
- Honeypot data from global networks
- CISA KEV catalog
- Security vendor reports
- Real-world exploitation patterns
- 1,100+ variables analyzed by ML model

**API Access:**
```bash
# Single CVE query
curl "https://api.first.org/data/v1/epss?cve=CVE-2022-26332"

# Batch query
curl "https://api.first.org/data/v1/epss?cve=CVE-2021-44228,CVE-2022-22965"

# Time series (30 days)
curl "https://api.first.org/data/v1/epss?cve=CVE-2022-25204&scope=time-series"
```

**Pros:**
- Evidence-based predictions using real exploitation data
- Daily updates reflect current threat landscape
- Significantly reduces false positives
- Free, publicly available API
- Proven accuracy

**Cons:**
- Only predicts next 30 days
- Requires CVE identifiers
- Scores fluctuate daily
- ML model is opaque (black box)

### 2. CVSS (Common Vulnerability Scoring System)

**What it is:** Industry-standard severity scoring system (v3.1/v4.0).

**Key Characteristics:**
- Score range: 0.0 to 10.0
- Focus: Theoretical severity
- Updates: Static (doesn't change)

**Components:**
- Base Score: Exploitability + Impact
- Temporal Score: Exploit maturity, remediation level
- Environmental Score: Organization-specific context

**Critical Limitation:** High CVSS score â‰  High exploitation likelihood

**Statistics:**
- Only 2.3% of CVSS â‰¥7.0 CVEs are actually exploited in the wild
- Prioritizing by CVSS alone creates 8x more remediation work

**Use Case:** Best for impact assessment, not exploitation prediction

### 3. KEV (Known Exploited Vulnerabilities)

**What it is:** CISA's catalog of CVEs confirmed as actively exploited in the wild.

**Key Characteristics:**
- Binary indicator (in catalog or not)
- Coverage: ~1,000 CVEs (vs 200,000+ total)
- Confidence: Highest (proven exploitation)
- Updates: Continuous

**Strengths:**
- Authoritative government source
- Highest confidence signal
- Mandated for US federal agencies
- Free, publicly accessible

**Limitations:**
- Limited coverage (only ~0.5% of all CVEs)
- Reactive (only after exploitation confirmed)
- No severity/impact information
- Binary only (no granularity)

**Use Case:** Should always elevate priority when present

### 4. CWE Exploitability

**CWE Top 25 Most Dangerous (2024):**

| Rank | CWE | Name | Exploitability |
|------|-----|------|---------------|
| 1 | CWE-79 | Cross-Site Scripting (XSS) | Very High |
| 2 | CWE-89 | SQL Injection | Critical |
| 3 | CWE-787 | Out-of-Bounds Write | High |
| 4 | CWE-22 | Path Traversal | Critical |
| 5 | CWE-287 | Improper Authentication | Very High |
| 6 | CWE-78 | OS Command Injection | Critical |
| 7 | CWE-862 | Missing Authorization | High |
| 8 | CWE-94 | Code Injection | Critical |
| 9 | CWE-352 | CSRF | Medium |
| 10 | CWE-434 | Unrestricted File Upload | High |

**Exploitability Weighting:**
- Critical (Weight: 3.0): Injection, Path Traversal, Auth Bypass
- High (Weight: 2.0): XSS, Memory Corruption, File Upload
- Medium (Weight: 1.5): CSRF, Information Disclosure
- Low (Weight: 1.0): Configuration Issues, DoS

## Scoring System Comparison

| System | What it Measures | Accuracy | Cost | Updates | Best For |
|--------|-----------------|----------|------|---------|----------|
| **EPSS** | Exploitation probability | High | Free | Daily | Prioritization |
| **CVSS** | Vulnerability severity | Medium | Free | Static | Impact assessment |
| **KEV** | Confirmed exploitation | Highest | Free | Continuous | Immediate action |
| **VPR** (Tenable) | Risk + Threat | High | Paid | Daily | Tenable customers |
| **SSVC** | Decision framework | Medium | Free | N/A | Org context |

## Recommended Approach

### Phase 1: MVP - Simple Scoring (No External Dependencies)

**Formula:**
```
Base_Score = (CriticalÃ—25 + HighÃ—15 + MediumÃ—5 + LowÃ—1) / (Total_CVEs + 1)

KEV_Multiplier = 1 + (KEV_Count Ã— 0.5)

High_Risk_CWE_Ratio = Count_of_Critical_High_CWEs / Total_CWE_Count
CWE_Modifier = 1 + (High_Risk_CWE_Ratio Ã— 0.3)

Exploitability_Score = Min(Base_Score Ã— KEV_Multiplier Ã— CWE_Modifier, 100)
```

**Score Ranges:**
- 0-20: Low
- 21-40: Medium
- 41-60: High
- 61-100: Critical

**Advantages:**
- Uses only existing data (CVE counts, KEV, CWE)
- No external API dependencies
- Fast, stable scores
- Simple implementation

**Disadvantages:**
- Less accurate than EPSS-based approach
- Doesn't use real exploitation data
- May underestimate well-exploited low-CVE technologies

### Phase 2: Production - EPSS Integration

**Formula:**
```
Exploitability_Score = 100 Ã— [
  (EPSS_Aggregate Ã— 0.5) +
  (CVSS_Impact Ã— 0.3) +
  (KEV_Factor Ã— 0.15) +
  (CWE_Exploitability Ã— 0.05)
]

Where:

EPSS_Aggregate = Î£(EPSS_i Ã— CVSS_i) / Î£(CVSS_i)
  (weighted average of EPSS scores across all CVEs)

CVSS_Impact = (CriticalÃ—10 + HighÃ—7 + MediumÃ—4 + LowÃ—1) / (Total_CVEs Ã— 10)
  (normalized severity distribution)

KEV_Factor = Min(KEV_Count / Max(Total_CVEs, 1), 1.0) Ã— 2.0
  If any KEV present: multiply final score by 1.5

CWE_Exploitability = Î£(CWE_Count_i Ã— CWE_Weight_i) / (Total_CWEs Ã— 3.0)
  Weights: Critical=3.0, High=2.0, Medium=1.5, Low=1.0
```

**Component Weighting:**
- EPSS (50%): Primary exploitation predictor
- CVSS (30%): Severity/impact component
- KEV (15%): Confirmed exploitation boost
- CWE (5%): Weakness-specific factor

**Advantages:**
- Evidence-based via EPSS
- Industry-leading accuracy
- Daily updates reflect current threats
- Proven 8x efficiency improvement

**Disadvantages:**
- Requires EPSS API integration
- Daily score fluctuations
- More complex implementation
- Depends on external service

### Example Calculation

**Angular (51 CVEs, 0 KEV):**

**Phase 1 Calculation:**
```
Base_Score = (3Ã—25 + 6Ã—15 + 30Ã—5 + 0Ã—1) / 52
           = (75 + 90 + 150) / 52 = 6.06

KEV_Multiplier = 1 + (0 Ã— 0.5) = 1.0

High_Risk_CWE_Ratio = 38/51 = 0.745 (XSS is high-risk)
CWE_Modifier = 1 + (0.745 Ã— 0.3) = 1.224

Score = 6.06 Ã— 1.0 Ã— 1.224 = 7.42

Angular: 7.42/100 (Low)
```

**Phase 2 Calculation (with EPSS):**
```
Assume avg EPSS: 0.15 for Critical, 0.08 for High, 0.03 for Medium

EPSS_Aggregate = (3Ã—0.15Ã—10 + 6Ã—0.08Ã—7 + 30Ã—0.03Ã—4) / (30+42+120)
               = 11.46 / 192 = 0.060

CVSS_Impact = 192 / 510 = 0.376

KEV_Factor = 0

CWE_Exploitability = (38Ã—2.0 + 8Ã—1.5 + 5Ã—1.5) / 153
                   = 95.5 / 153 = 0.624

Score = 100 Ã— [(0.060Ã—0.5) + (0.376Ã—0.3) + (0Ã—0.15) + (0.624Ã—0.05)]
      = 100 Ã— [0.030 + 0.113 + 0 + 0.031]
      = 17.4

Angular: 17.4/100 (Low-Medium)
```

## Data Requirements

### Already Available:
- CVE counts (Critical, High, Medium, Low) âœ“
- KEV counts âœ“
- CWE categories and counts âœ“
- Technology metadata âœ“

### Need to Add (Phase 2):
- EPSS scores per CVE (from API)
- Daily update mechanism
- Score caching layer
- CWE-to-exploitability mapping (static config)

### Proposed Schema Extension:

```json
{
  "slug": "frontend.angular",
  "security": {
    "cve": {
      "stats": { /* existing */ },
      "epss": {
        "aggregate_score": 0.060,
        "max_score": 0.150,
        "high_risk_count": 5,
        "updated": "2025-10-16T00:00:00Z"
      }
    },
    "weaknesses": { /* existing CWE data */ },
    "exploitability": {
      "score": 17.4,
      "category": "Low-Medium",
      "version": "v2.0",
      "updated": "2025-10-16T12:00:00Z",
      "components": {
        "epss": 0.060,
        "cvss_impact": 0.376,
        "kev_factor": 0.0,
        "cwe_factor": 0.624
      }
    }
  }
}
```

## Implementation Challenges

### 1. EPSS API Integration
- **Challenge:** Rate limits, availability
- **Mitigation:** Cache aggressively, batch queries, CSV fallback

### 2. Score Stability
- **Challenge:** Daily fluctuations may confuse users
- **Mitigation:** Show trends, moving averages, highlight significant changes

### 3. Context Interpretation
- **Challenge:** Same score may mean different urgency for different assets
- **Mitigation:** Multi-level display (score + raw data + context)

### 4. Technology Diversity
- **Challenge:** Comparing CMS to framework to library is apples-to-oranges
- **Mitigation:** Normalize within categories, use percentile rankings

### 5. Data Quality
- **Challenge:** Not all technologies have complete CVE/CWE data
- **Mitigation:** Fallback scoring, "Insufficient Data" category

## Best Practices

### 1. Never Rely on Single Metric
Always combine multiple indicators (EPSS + KEV + CVSS + CWE).

### 2. EPSS + KEV > CVSS Alone
Exploitation likelihood beats theoretical severity for prioritization.

### 3. Update Frequently
Threat landscape changes daily; scores should reflect current state.

### 4. Provide Full Context
Don't just show a number - explain components, show trends, link to sources.

### 5. Validate and Iterate
Track real-world exploitation vs predictions; tune formula based on results.

### 6. Make Actionable
Score should drive decisions (patch now vs later), not just inform.

## User-Facing Presentation

**Recommended Display:**

```
Technology: WordPress
Exploitability Score: 74 / 100 (High Risk)

â”Œâ”€ Score Breakdown â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EPSS Probability: 65% (exploitation in 30d)  â”‚
â”‚ KEV Status: 2 actively exploited CVEs        â”‚
â”‚ CVE Distribution: 3 Critical, 12 High, 45 Medâ”‚
â”‚ Top Weakness: SQL Injection (CWE-89)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Priority: Schedule remediation within 2 weeks
Impact: Affects 15 domains
```

**Color Coding:**
- 0-20: ğŸŸ¢ Green (Low)
- 21-40: ğŸŸ¡ Yellow (Medium)
- 41-60: ğŸŸ  Orange (High)
- 61-100: ğŸ”´ Red (Critical)

**Actionable Insights:**
- Priority level (Immediate, Urgent, Scheduled, Monitor)
- Recommended timeline
- Affected asset count
- Specific CVEs to patch first (highest EPSS + KEV)

## Industry Examples

### Qualys TruRisk
- Combines asset criticality, QDS (similar to EPSS), and external exposure
- Non-linear scaling for vulnerability counts
- External exposure multiplier

### Tenable VPR
- Technical Impact (CVSS) + Threat Intelligence
- Seven drivers including age, exploit maturity, trending status
- Daily updates, 0.1-10.0 scale

### Security Scorecards (BitSight, SecurityScorecard)
- Letter grades (A-F) based on external scan data
- Composite risk across multiple domains
- Industry benchmarking

## Recommendations Summary

### Immediate (Week 1-2):
1. Implement Phase 1 simple scoring
2. Add to findings.json structure
3. Display in HTML report alongside CVE/CWE data
4. Validate with sample technologies

### Short-term (Week 3-6):
1. Integrate EPSS API client
2. Implement daily score caching
3. Upgrade to Phase 2 hybrid formula
4. A/B test vs Phase 1 scores

### Long-term (Week 7-12):
1. Add technology age/maintenance tracking
2. Asset prevalence weighting
3. Trend analysis and alerting
4. Feedback loop and formula tuning

### Governance:
- Version scoring formulas (v1.0, v2.0)
- Document methodology clearly
- Provide "Explain Score" feature
- Track validation metrics (predictions vs reality)

## References

### Official Documentation:
- FIRST EPSS: https://www.first.org/epss/
- CISA KEV Catalog: https://www.cisa.gov/known-exploited-vulnerabilities
- CVSS v3.1: https://www.first.org/cvss/specification-document
- CWE Top 25: https://cwe.mitre.org/top25/

### Research Papers:
- "Exploit Prediction Scoring System (EPSS)" - ACM Digital Threats (2021)
- Cyentia Institute EPSS Performance Study (2024)
- "Early and Realistic Exploitability Prediction" - ACM TOSEM (2024)

### Industry Resources:
- Qualys TruRisk Documentation
- Tenable VPR Whitepaper
- OWASP Risk Rating Methodology

## Conclusion

Implementing an exploitability scoring system is both feasible and highly recommended. A hybrid approach combining EPSS (exploitation probability), KEV (confirmed threats), CVSS (severity), and CWE (weakness types) provides the most accurate prioritization.

**Key Benefits:**
- 8x reduction in remediation workload
- 80% reduction in false positives
- Evidence-based prioritization
- Industry-proven approach

**Recommended Path:**
Start with simple severity-based scoring (Phase 1) for quick validation, then integrate EPSS (Phase 2) for production accuracy. This phased approach balances speed-to-market with long-term sophistication.

---

**Document Status:** Research Complete
**Next Steps:** Review with team, approve implementation plan
**Owner:** Security Research Team
**Last Updated:** October 16, 2025
